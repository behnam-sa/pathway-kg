{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graph Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kmgN5oJGLhLT",
        "riUQd_gG9PRY",
        "GTBimSEf9jkW",
        "Rzo66rzzAdME",
        "UZo0DJkiAhpb",
        "MjptK0FbKAxd",
        "Do6jyX4VOIMT",
        "dpqPM4awUBAA",
        "pALKUNIP_lMJ",
        "tNvebpdt_3KH",
        "3T3u_MuyCuDO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmgN5oJGLhLT"
      },
      "source": [
        "# Eternal Module Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FjoSWK_TT4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae0860dc-e109-4431-a3e1-8faac51b6fd1"
      },
      "source": [
        "! pip install openbiolink"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openbiolink\n",
            "  Downloading openbiolink-0.1.4-py3-none-any.whl (226 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▌                              | 10 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 20 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 30 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 40 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 81 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 226 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.29.1 in /usr/local/lib/python3.7/dist-packages (from openbiolink) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from openbiolink) (1.21.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from openbiolink) (7.1.2)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.7/dist-packages (from openbiolink) (1.3.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from openbiolink) (1.11.0+cu113)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->openbiolink) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->openbiolink) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.4->openbiolink) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->openbiolink) (4.2.0)\n",
            "Installing collected packages: openbiolink\n",
            "Successfully installed openbiolink-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyVfad59VpsU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d00a143-6707-4319-839b-53ba642dbd3e"
      },
      "source": [
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.9 MB 615 kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 1.0 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module Imports"
      ],
      "metadata": {
        "id": "riUQd_gG9PRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openbiolink.obl2021 import OBL2021Dataset, OBL2021Evaluator\n",
        "import torch\n",
        "from torch.nn import Module,\\\n",
        "                     ModuleList,\\\n",
        "                     Embedding,\\\n",
        "                     BatchNorm1d,\\\n",
        "                     ReLU,\\\n",
        "                     Linear,\\\n",
        "                     BCEWithLogitsLoss,\\\n",
        "                     MarginRankingLoss,\\\n",
        "                     CrossEntropyLoss,\\\n",
        "                     Dropout\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "# import torch_geometric as PyG\n",
        "# from torch_geometric.data import Data\n",
        "# from torch_geometric.nn.conv import RGCNConv\n",
        "# from torch_geometric.utils import to_networkx\n",
        "# import networkx as nx\n",
        "# import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from typing import NoReturn\n",
        "import typing\n",
        "# import time\n",
        "from enum import Enum\n",
        "# from datetime import datetime\n",
        "# from collections import defaultdict"
      ],
      "metadata": {
        "id": "SYfjWfsh9UE5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Loading + Preprocessing"
      ],
      "metadata": {
        "id": "GTBimSEf9jkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = OBL2021Dataset()\n",
        "evaluator = OBL2021Evaluator()\n",
        "kg = torch.cat((dataset.training, dataset.validation, dataset.testing), dim=0)\n",
        "entities = dataset.candidates\n",
        "train_set = dataset.training\n",
        "dev_set = dataset.validation\n",
        "test_set = dataset.testing"
      ],
      "metadata": {
        "id": "0GiwxvQK9t-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67525789-9bbd-4500-e2e7-a6b3f44412b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset not found, downloading to /content/obl2021 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "KGID_HQ_DIR.zip: 45.2MB [00:24, 1.92MB/s]                            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PcUcz0z-Kaj9",
        "outputId": "9bdce8f8-437c-485a-9b1b-45fd3541ae66"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Triples:     \\n     Train 4192002\\n     Valid 186301\\n     Test  180964\\n# Relations:   28\\n# Entities:    180992\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.num_relations"
      ],
      "metadata": {
        "id": "vkwcwyX3DLQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090b4fda-43ac-4a9c-ce4f-f92bb7fa32c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cat ./obl2021/entities.tsv"
      ],
      "metadata": {
        "id": "y78JTdqVL1gZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "Rzo66rzzAdME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DistMult"
      ],
      "metadata": {
        "id": "UZo0DJkiAhpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DistMultModel(Module):\n",
        "  def __init__(self, num_entities: int, num_relations: int, embedding_size: int) -> NoReturn:\n",
        "    super(DistMultModel, self).__init__()\n",
        "    self.num_entities = num_entities\n",
        "    self.num_relations = num_relations\n",
        "    self.embedding_size = embedding_size\n",
        "    self.entity_encoder = Embedding(self.num_entities, self.embedding_size)\n",
        "    self.relation_encoder = Embedding(self.num_relations, self.embedding_size)\n",
        "\n",
        "  def _encode_triplets(self, triplets: torch.Tensor) -> tuple:\n",
        "    h_heads = self.entity_encoder(triplets[:, 0])\n",
        "    h_tails = self.entity_encoder(triplets[:, 2])\n",
        "    h_relations = self.relation_encoder(triplets[:, 1])\n",
        "    return h_heads, h_relations, h_tails\n",
        "\n",
        "  def forward(self, data_triplets: tuple((torch.Tensor, torch.Tensor))) -> tuple:\n",
        "    p_triplets, n_triplets = data_triplets\n",
        "    p_heads, p_relations, p_tails = self._encode_triplets(p_triplets)\n",
        "    n_heads, n_relations, n_tails = self._encode_triplets(n_triplets)\n",
        "\n",
        "    p_scores = (p_heads * p_relations * p_tails).sum(-1)\n",
        "    n_scores = (n_heads * n_relations * n_tails).sum(-1)\n",
        "\n",
        "    return p_scores, n_scores"
      ],
      "metadata": {
        "id": "g8UwcJ7lAkCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RESCAL"
      ],
      "metadata": {
        "id": "MjptK0FbKAxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RESCALModel(Module):\n",
        "  def __init__(self, num_entities: int, num_relations: int, embedding_size: int) -> NoReturn:\n",
        "    super(RESCALModel, self).__init__()\n",
        "    self.num_entities = num_entities\n",
        "    self.num_relations = num_relations\n",
        "    self.embedding_size = embedding_size\n",
        "    self.entity_encoder = Embedding(self.num_entities, self.embedding_size)\n",
        "    self.relation_encoder = Embedding(self.num_relations, self.embedding_size * self.embedding_size)\n",
        "\n",
        "  def _encode_triplets(self, triplets: torch.Tensor) -> tuple:\n",
        "    h_heads = self.entity_encoder(triplets[:, 0])\n",
        "    h_tails = self.entity_encoder(triplets[:, 2])\n",
        "    h_relations = self.relation_encoder(triplets[:, 1]).reshape(-1, self.embedding_size, self.embedding_size)\n",
        "    return h_heads, h_relations, h_tails\n",
        "\n",
        "  def forward(self, data_triplets: tuple((torch.Tensor, torch.Tensor))) -> tuple:\n",
        "    p_triplets, n_triplets = data_triplets\n",
        "    p_heads, p_relations, p_tails = self._encode_triplets(p_triplets)\n",
        "    n_heads, n_relations, n_tails = self._encode_triplets(n_triplets)\n",
        "\n",
        "    n_scores = torch.matmul(\n",
        "        torch.matmul(n_heads.reshape(-1, 1, self.embedding_size), n_relations),\n",
        "        n_tails.reshape(-1, self.embedding_size, 1)\n",
        "    )\n",
        "\n",
        "    p_scores = torch.matmul(\n",
        "        torch.matmul(p_heads.reshape(-1, 1, self.embedding_size), p_relations),\n",
        "        p_tails.reshape(-1, self.embedding_size, 1)\n",
        "    )\n",
        "\n",
        "    return p_scores.reshape(-1), n_scores.reshape(-1)"
      ],
      "metadata": {
        "id": "XO4i3tLkKDDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hinge Loss"
      ],
      "metadata": {
        "id": "Do6jyX4VOIMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HingeLoss(Module):\n",
        "  def __init__(self, margin):\n",
        "    super(HingeLoss, self).__init__()\n",
        "    self.margin = margin\n",
        "    self.loss_fn = MarginRankingLoss(self.margin)\n",
        "\n",
        "  def forward(self, p_scores: torch.Tensor, n_scores: torch.Tensor) -> torch.Tensor:\n",
        "    positive = p_scores.repeat(n_scores.shape)\n",
        "    negative = n_scores.repeat(p_scores.shape)\n",
        "\n",
        "    return self.loss_fn(positive, negative, torch.ones(n_scores.shape[0] * p_scores.shape[0]).to(positive.device))\n"
      ],
      "metadata": {
        "id": "v3eP3OgBOQbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Neural Network"
      ],
      "metadata": {
        "id": "dpqPM4awUBAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = Data(\n",
        "    x=gm.dataset.candidates, \n",
        "    edge_index=gm.dataset.training[:, [0, 2]].t().contiguous(), \n",
        "    edge_type=gm.dataset.training[:, 1].t().contiguous()\n",
        ")\n",
        "# conv = RGCNConv(4, 8, gm.num_relations)\n",
        "# emb = Embedding(gm.num_entities, 4)\n",
        "# train_data.x = emb(train_data.x)\n",
        "# # train_data\n",
        "# conv(x=train_data.x, edge_index=train_data.edge_index, edge_type=train_data.edge_type)"
      ],
      "metadata": {
        "id": "VCXubWK5UTwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(Module):\n",
        "  def __init__(self, num_entities: int, num_relations: int, embedding_dim: int, conv_dims: tuple, dropout):\n",
        "    super(GNN, self).__init__()\n",
        "    self.num_entities = num_entities\n",
        "    self.num_relations = num_relations\n",
        "    self.embedding_dim = embedding_dim \n",
        "    self.conv_channels = [self.embedding_dim] + list(conv_dims)\n",
        "    self.dropout = dropout\n",
        "\n",
        "    self.shallow_embedding = Embedding(self.num_entities, self.embedding_dim)\n",
        "    self.emb_bn = BatchNorm1d(self.embedding_dim)\n",
        "    self.conv = ModuleList([\n",
        "                RGCNConv(dim, self.conv_channels[index + 1], num_relations=self.num_relations)\n",
        "                for index, dim in enumerate(self.conv_channels[:-1])\n",
        "    ])\n",
        "    self.conv_bn = ModuleList([\n",
        "                        BatchNorm1d(dim)\n",
        "                        for dim in self.conv_channels[1:]\n",
        "    ])\n",
        "    self.activation = ReLU()\n",
        "    self.dropout = Dropout(p=self.dropout)\n",
        "\n",
        "  def _node_encoder(self, data: Data):\n",
        "    x = data.x\n",
        "    x = self.shallow_embedding(x)\n",
        "    x = self.emb_bn(x)\n",
        "    for conv, conv_bn in zip(self.conv, self.conv_bn):\n",
        "      x = conv(x, data.edge_index, data.edge_type) \n",
        "      x = conv_bn(x)\n",
        "      x = self.activation(x)\n",
        "      x = self.dropout(x)\n",
        "    return x\n",
        "  \n",
        "  def forward(self, data: Data):\n",
        "    nodes_h = self._node_encoder(data)\n",
        "    ## decoding part of the auto-encoder\n",
        "\n",
        "    return nodes_h\n"
      ],
      "metadata": {
        "id": "s8qaQzPVZMDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = Data(\n",
        "    x=gm.dataset.candidates, \n",
        "    edge_index=gm.dataset.training[: -100, [0, 2]].t().contiguous(), \n",
        "    edge_type=gm.dataset.training[:-100, 1].t().contiguous(),\n",
        "    \n",
        "\n",
        ")\n",
        "gnn = GNN(gm.num_entities, gm.num_relations, 4, [8, 10, 12], 0.3)\n",
        "gnn(train_data)[15], train_data.x[15]"
      ],
      "metadata": {
        "id": "NL8I7cwRcpiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Miner"
      ],
      "metadata": {
        "id": "pALKUNIP_lMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphMiner():\n",
        "  def __init__(self, dataset, device: str, cache_size: int=None, replacement_size: int=None) -> NoReturn:\n",
        "    self.device = device\n",
        "    self.dataset = dataset\n",
        "    self.training = self.dataset.training.to(self.device)\n",
        "    self.validation = self.dataset.validation.to(self.device)\n",
        "    self.testing = self.dataset.testing.to(self.device)\n",
        "    self.candidates = self.dataset.candidates.to(self.device)\n",
        "    if cache_size and replacement_size:\n",
        "      self.cache_size = cache_size\n",
        "      self.replacement_size = replacement_size\n",
        "      self.head_cache = (torch.rand(dataset.num_relations, entities.shape[0], cache_size) * entities.shape[0] - 1).round().long().to(self.device)\n",
        "      self.tail_cache = (torch.rand(entities.shape[0], dataset.num_relations, cache_size) * entities.shape[0] - 1).round().long().to(self.device)\n",
        "\n",
        "    self.num_entities = self.dataset.num_entities\n",
        "    self.num_relations = self.dataset.num_relations\n",
        "\n",
        "  def uniform_negative_sample(self, batch):\n",
        "    batch_size = batch.shape[0]\n",
        "\n",
        "    head_relation = batch[:, (0, 1)].repeat(self.candidates.shape[0], 1)\n",
        "    relation_tail = batch[:, (1, 2)].repeat(self.candidates.shape[0], 1)\n",
        "\n",
        "    entities = self.candidates.reshape(-1, 1).repeat(batch_size, 1)\n",
        "    entities = torch.cat(torch.split(entities, self.candidates.shape[0]), -1).reshape(-1, 1)\n",
        "\n",
        "    corrupted_head_triplets = torch.cat(\n",
        "        (entities, relation_tail), \n",
        "        -1\n",
        "    )\n",
        "    corrupted_tail_triplets = torch.cat(\n",
        "        (head_relation, entities), \n",
        "        -1\n",
        "    )\n",
        "\n",
        "    negative_triplets = torch.cat((corrupted_head_triplets, corrupted_tail_triplets))\n",
        "    negative_triplets = torch.cat(torch.split(negative_triplets, batch_size), -1).reshape(batch_size, -1, 3)\n",
        "    indcs = (torch.rand(batch_size) * (self.candidates.shape[0] * 2 - 1)).round().long().to(self.device)\n",
        "    splits = torch.split(negative_triplets.reshape(-1, 3), self.candidates.shape[0] * 2)\n",
        "    splits = torch.stack(splits).reshape(-1, 3)\n",
        "\n",
        "    indcs += torch.arange(batch_size) * (2 * self.candidates.shape[0])\n",
        "    negative_samples = splits[indcs]\n",
        "    return negative_samples\n",
        "\n",
        "  def cache_negative_sample(self, batch, scoring_function):\n",
        "    batch_size = batch.shape[0]\n",
        "    heads = batch[:, 0]\n",
        "    tails = batch[:, 2]\n",
        "    relations = batch[:, 1]\n",
        "\n",
        "    candidate_heads = self.head_cache[relations, tails]\n",
        "    candidate_tails = self.tail_cache[heads, relations]\n",
        "\n",
        "    corrupt_head_indcs = (torch.rand(batch_size) * (self.cache_size - 1)).round().long().to(self.device) # 1 for each item in the batch?\n",
        "    corrupt_tail_indcs = (torch.rand(batch_size) * (self.cache_size - 1)).round().long().to(self.device) # 1 for each item in the batch?\n",
        "\n",
        "    corrupt_head_indcs += torch.arange(batch_size) * self.cache_size\n",
        "    corrupt_heads = candidate_heads.reshape(-1)[corrupt_head_indcs]\n",
        "\n",
        "    corrupt_tail_indcs += torch.arange(batch_size) * self.cache_size\n",
        "    corrupt_tails = candidate_tails.reshape(-1)[corrupt_tail_indcs]\n",
        "\n",
        "    corrupted_head_triplets = torch.cat((corrupt_heads.reshape(-1, 1), batch[:, (1, 2)]), -1)\n",
        "    corrupted_tail_triplets = torch.cat((batch[:, (0, 1)], corrupt_tails.reshape(-1, 1)), -1)\n",
        "    negative_triplets = torch.cat((corrupted_head_triplets, corrupted_tail_triplets), 0)\n",
        "\n",
        "    negative_triplets = torch.cat(torch.split(negative_triplets, batch_size), -1).reshape(batch_size, -1, 3)\n",
        "    indcs = torch.rand(batch_size).round().long().to(self.device)\n",
        "    splits = torch.split(negative_triplets.reshape(-1, 3), 1 * 2)\n",
        "\n",
        "    splits = torch.stack(splits).reshape(-1, 3)\n",
        "    indcs += torch.arange(batch_size) * (1 * 2)\n",
        "    negative_samples = splits[indcs]\n",
        "    self.update_caches(batch, scoring_function)\n",
        "    return negative_samples\n",
        "\n",
        "  def _update_cache(self, batch, scoring_function, head_or_tail):\n",
        "    batch_size = batch.shape[0]\n",
        "    heads = batch[:, 0]\n",
        "    tails = batch[:, 2]\n",
        "    relations = batch[:, 1]\n",
        "\n",
        "    replacement_candidates = (\n",
        "          torch.rand(\n",
        "              batch_size * self.replacement_size\n",
        "          ) * (self.candidates.shape[0] - 1)).round().long().reshape(batch_size, self.replacement_size).to(self.device)\n",
        "\n",
        "    if head_or_tail == 'head':\n",
        "      current_entities = self.head_cache[relations, tails]\n",
        "    elif head_or_tail == 'tail':\n",
        "      current_entities = self.tail_cache[heads, relations]\n",
        "\n",
        "    entities_pool = torch.cat((current_entities, replacement_candidates), -1)\n",
        "    if head_or_tail == 'head':\n",
        "      partial_triplets = batch[:, 1:]\n",
        "    elif head_or_tail == 'tail':\n",
        "      partial_triplets = batch[:, :2]\n",
        "    partial_triplets = partial_triplets.repeat(entities_pool.shape[1], 1)\n",
        "\n",
        "    partial_triplets = torch.cat(torch.split(partial_triplets, batch_size), -1).reshape(batch_size, -1, 2).reshape(-1, 2)\n",
        "\n",
        "    if head_or_tail == 'head':\n",
        "      pool = torch.cat((entities_pool.reshape(-1, 1), partial_triplets), -1)\n",
        "    elif head_or_tail == 'tail':\n",
        "      pool = torch.cat((partial_triplets, entities_pool.reshape(-1, 1)), -1)\n",
        "\n",
        "    dummy = torch.ones(1, 3).long().to(self.device)\n",
        "    scoring_function.eval()\n",
        "    with torch.no_grad():\n",
        "      scores = scoring_function((dummy, pool))[1]\n",
        "    fitness = F.softmax(scores, 0)\n",
        "    split = torch.stack(torch.split(fitness, self.replacement_size + self.cache_size))\n",
        "\n",
        "    next_entities_indcs = split.multinomial(num_samples=self.cache_size)\n",
        "    if head_or_tail == 'head':\n",
        "      self.head_cache[relations, tails] = torch.take(entities_pool, next_entities_indcs)\n",
        "    elif head_or_tail == 'tail':\n",
        "      self.tail_cache[heads, relations] = torch.take(entities_pool, next_entities_indcs)\n",
        "\n",
        "  def update_caches(self, batch, scoring_function):\n",
        "    self._update_cache(batch, scoring_function, 'head')\n",
        "    self._update_cache(batch, scoring_function, 'tail')\n",
        "\n",
        "  def train(self, model: Module, data, optimizer: torch.optim, loss_fn) -> tuple((torch.float, torch.Tensor, torch.Tensor)):\n",
        "    optimizer.zero_grad()\n",
        "    model.train()\n",
        "\n",
        "    positive, negative = model(data) # forward pass\n",
        "\n",
        "    loss = loss_fn(positive, negative) # margin ranking loss\n",
        "\n",
        "    loss.backward() # back propagation\n",
        "    optimizer.step() # parameter updates\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def _ranks(self, model, batch):\n",
        "    batch_size = batch.shape[0]\n",
        "\n",
        "    head_relation = batch[:, (0, 1)].repeat(self.candidates.shape[0], 1)\n",
        "    relation_tail = batch[:, (1, 2)].repeat(self.candidates.shape[0], 1)\n",
        "\n",
        "    entities = self.candidates.reshape(-1, 1).repeat(batch_size, 1)\n",
        "    entities = torch.cat(torch.split(entities, self.candidates.shape[0]), -1).reshape(-1, 1)\n",
        "\n",
        "    corrupted_head_triplets = torch.cat(\n",
        "        (entities, relation_tail), \n",
        "        -1\n",
        "    )\n",
        "    corrupted_tail_triplets = torch.cat(\n",
        "        (head_relation, entities), \n",
        "        -1\n",
        "    )\n",
        "    corrupted_head_triplets = torch.cat(torch.split(corrupted_head_triplets, batch_size), -1).reshape(batch_size, -1, 3)\n",
        "    corrupted_tail_triplets = torch.cat(torch.split(corrupted_tail_triplets, batch_size), -1).reshape(batch_size, -1, 3)\n",
        "\n",
        "    heads = batch[:, 0]\n",
        "    tails = batch[:, 2]\n",
        "\n",
        "    dummy = torch.ones(1, 3).long().to(self.device)\n",
        "\n",
        "    model.eval()\n",
        "    head_scores = model(\n",
        "        (dummy, corrupted_head_triplets.reshape(-1, 3))\n",
        "    )[1].reshape(batch_size, -1)\n",
        "    head_ranks = (head_scores.gather(dim=1, index=heads.reshape(-1, 1)) <= head_scores).sum(-1) # Max Policy\n",
        "\n",
        "    tail_scores = model(\n",
        "        (dummy, corrupted_tail_triplets.reshape(-1, 3))\n",
        "    )[1].reshape(batch_size, -1)\n",
        "    tail_ranks = (tail_scores.gather(dim=1, index=tails.reshape(-1, 1)) <= tail_scores).sum(-1)\n",
        "\n",
        "    return head_ranks.reshape(-1), tail_ranks.reshape(-1)\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def MRR(self, model, set_type, batch_size, use_tqdm=False):\n",
        "    if set_type == 'validation':\n",
        "      eval_set = self.validation\n",
        "    elif set_type == 'testing':\n",
        "      eval_set = self.testing\n",
        "    else:\n",
        "      raise ValueError('Wrong data split specified.')\n",
        "    \n",
        "    sum = 0\n",
        "    size = 0\n",
        "    wrapper = tqdm if use_tqdm else (lambda z: z)\n",
        "    for batch in wrapper(torch.split(eval_set, batch_size)):\n",
        "      head_ranks, tail_ranks = self._ranks(model, batch)\n",
        "      sum += (1 / head_ranks).sum() + (1 / tail_ranks).sum()\n",
        "      size += head_ranks.shape[0] + tail_ranks.shape[0]\n",
        "    return sum / size\n",
        "\n",
        "    \n",
        "      "
      ],
      "metadata": {
        "id": "DfkRLMsc_nHG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "tNvebpdt_3KH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gm = GraphMiner(dataset, 'cpu', 50, 50)\n",
        "dm = DistMultModel(gm.num_entities, gm.num_relations, 256)\n",
        "optimizer = Adam(dm.parameters(), weight_decay=3e-8)\n",
        "margin = 1\n",
        "criterion = HingeLoss(margin=margin)\n",
        "batch_size = 64\n",
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "7ZKLZPeX5h6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  train_batches = torch.split(gm.training, batch_size)\n",
        "  epoch_loss = 0\n",
        "  for batch in tqdm(train_batches):\n",
        "    negative = gm.cache_negative_sample(batch, dm)\n",
        "    epoch_loss += gm.train(dm, (batch, negative), optimizer, criterion)\n",
        "  print(f'Epoch {epoch}')\n",
        "  print(epoch_loss)  \n",
        "  if epoch % 10 == 0:\n",
        "    print(f'Validation MRR: {gm.MRR(dm, \"validation\", 64, True)}')"
      ],
      "metadata": {
        "id": "WLaXCuarUhdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rscl = RESCALModel(dataset.num_entities, gm.num_relations, 4).to('cuda')\n",
        "optm = Adam(rscl.parameters(), 1e-3)\n",
        "\n",
        "p = train_set[:100].to('cuda')\n",
        "n = gm.cache_negative_sample(p)\n",
        "# rscl((p, n))[0]"
      ],
      "metadata": {
        "id": "lRn0pwKSLAqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "  rscl.train()\n",
        "  p = train_set[:100].to('cuda')\n",
        "  n = gm.cache_negative_sample(p)\n",
        "  p_s, n_s = rscl((p, n))\n",
        "  loss = gm.margin_ranking_loss(p_s, n_s)\n",
        "  loss.backward()\n",
        "  optm.step()\n",
        "  print(loss.item())"
      ],
      "metadata": {
        "id": "nJqUJ4QeMQ5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
      ],
      "metadata": {
        "id": "SG1fLGKFNO8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Metric"
      ],
      "metadata": {
        "id": "3T3u_MuyCuDO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d87ZALUBYec9",
        "cellView": "form"
      },
      "source": [
        "#@title find_start_and_end_indcs() PRIVATE-FUNCTION { form-width: \"15%\" }\n",
        "def find_start_and_end_indcs(entity, relation, entity_type, kg_sorted):\n",
        "  up = kg_sorted.shape[0]\n",
        "  down = 0\n",
        "  indx = kg_sorted.shape[0] // 2\n",
        "  found = False\n",
        "  while up - down > 1:\n",
        "    if kg_sorted[indx][entity_type].item() == entity:\n",
        "      found = True\n",
        "      break \n",
        "    elif kg_sorted[indx][entity_type].item() >= entity: \n",
        "      up = indx\n",
        "      indx = (up + down) // 2\n",
        "    else:\n",
        "      down = indx \n",
        "      indx = (up + down) // 2\n",
        "  if not found:\n",
        "    return None\n",
        "  while 1:\n",
        "    indx += 1\n",
        "    try:\n",
        "      if not kg_sorted[indx][entity_type].item() == entity:\n",
        "        indx -= 1\n",
        "        end_indx = indx\n",
        "        break\n",
        "    except:\n",
        "      end_indx = indx - 1\n",
        "      break\n",
        "  \n",
        "\n",
        "  while 1:\n",
        "    indx -= 1\n",
        "    try:\n",
        "      if not kg_sorted[indx][entity_type].item() == entity:\n",
        "        indx += 1\n",
        "        start_indx = indx\n",
        "        break\n",
        "    except:\n",
        "      start_indx = indx + 1\n",
        "      break\n",
        "  indcs = torch.arange(start_indx, end_indx + 1)\n",
        "  tns = kg_sorted[indcs]\n",
        "  srt_indcs = torch.sort(tns[:, 1])[1]\n",
        "\n",
        "  msk = tns[srt_indcs][:, 1] == relation\n",
        "  okay_indcs = torch.nonzero(msk).reshape(-1)\n",
        "  return indcs[srt_indcs[okay_indcs]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYPeOqPxkFtD"
      },
      "source": [
        "#@title get_psuedo_negative_entities() FUNCTIONS { form-width: \"15%\" }\n",
        "def get_psuedo_negative_entities(entity, relation, corrupt_at, kg_sorted):\n",
        "  if corrupt_at == Global.HEAD_INDEX.value:\n",
        "    entity_type = Global.TAIL_INDEX.value \n",
        "  elif corrupt_at == Global.TAIL_INDEX.value:\n",
        "    entity_type = Global.HEAD_INDEX.value\n",
        "\n",
        "  indcs = find_start_and_end_indcs(entity, relation, entity_type, kg_sorted=kg_sorted)\n",
        "  \n",
        "  if indcs is not None:\n",
        "    fact_triplets_entities = kg_sorted[indcs][:, corrupt_at]\n",
        "    features_copy = features.detach().clone()\n",
        "    features_copy[fact_triplets_entities] = -1\n",
        "    non_negative_mask = features_copy >= 0\n",
        "    ret = torch.nonzero(non_negative_mask).reshape(-1)\n",
        "    return ret\n",
        "  else:\n",
        "    return features.to(Global.DEVICE.value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcSjKWmGyYuj"
      },
      "source": [
        "#@title evaluation_rank() PRIVATE-FUNCTION { form-width: \"10%\" }\n",
        "@torch.no_grad()\n",
        "def evaluation_rank(model, eval_set, messaging_set):\n",
        "  h_pred_top10 = list()\n",
        "  t_pred_top10 = list()\n",
        "\n",
        "  for eval_triplet in tqdm(eval_set):\n",
        "    #use tqdm\n",
        "    head = eval_triplet[Global.HEAD_INDEX.value].item()\n",
        "    relation = eval_triplet[Global.RELATION_INDEX.value].item()\n",
        "    tail = eval_triplet[Global.TAIL_INDEX.value].item()\n",
        "\n",
        "    corrupted_tails = get_psuedo_negative_entities(\n",
        "        entity=head, \n",
        "        corrupt_at=Global.TAIL_INDEX.value, \n",
        "        kg_sorted=kg_sorted_heads\n",
        "    )\n",
        "    \n",
        "    num_psuedo_negative_triples = corrupted_tails.shape[0]\n",
        "    psuedo_negative_triplets_corrupted_tail = torch.vstack(\n",
        "        (\n",
        "            torch.ones(num_psuedo_negative_triples).to(Global.DEVICE.value).type(torch.long) * head,\n",
        "            torch.ones(num_psuedo_negative_triples).to(Global.DEVICE.value).type(torch.long) * relation,\n",
        "            corrupted_tails\n",
        "        )\n",
        "    ).t().to(Global.DEVICE.value)\n",
        "\n",
        "    corrupted_heads = get_psuedo_negative_entities(\n",
        "        entity=tail, \n",
        "        corrupt_at=Global.HEAD_INDEX.value, \n",
        "        kg_sorted=kg_sorted_tails\n",
        "    )\n",
        "\n",
        "    num_psuedo_negative_triples = corrupted_heads.shape[0]\n",
        "    psuedo_negative_triplets_corrupted_head = torch.vstack(\n",
        "        (\n",
        "            corrupted_heads,\n",
        "            torch.ones(num_psuedo_negative_triples).to(Global.DEVICE.value).type(torch.long) * relation,\n",
        "            torch.ones(num_psuedo_negative_triples).to(Global.DEVICE.value).type(torch.long) * tail\n",
        "        )\n",
        "    ).t().to(Global.DEVICE.value)\n",
        "\n",
        "    # eval_triplet: (h, r, t)\n",
        "    # psuedo_negative_triplets_head: (h′, r, t) for all h′\n",
        "    # psuedo_negative_triplets_tail: (h, r, t′) for all t′\n",
        "\n",
        "    # train_set being the messaging graph, calculate the score for (h, r, t)\n",
        "    # train_set being the messaging graph, calculate the scores for all (h′, r, t)\n",
        "    # train_set being the messaging graph, calculate the scores for all (h, r, t′)\n",
        "\n",
        "    graph_data_for_object_tail = graph_data_maker(\n",
        "      messaging=messaging_set,\n",
        "      supervision=eval_triplet.reshape(1, 3),\n",
        "      negative_samples=psuedo_negative_triplets_corrupted_tail,\n",
        "      x=features.to(Global.DEVICE.value),\n",
        "      x_feature='one-hot'\n",
        "    )\n",
        "\n",
        "    graph_data_for_object_head = graph_data_maker(\n",
        "            messaging=messaging_set,\n",
        "            supervision=eval_triplet.reshape(1, 3),\n",
        "            negative_samples=psuedo_negative_triplets_corrupted_head,\n",
        "            x=features.to(Global.DEVICE.value),\n",
        "            x_feature='one-hot'\n",
        "    )\n",
        "\n",
        "    model.eval()\n",
        "    scores_for_object_tail = torch.cat(model(graph_data_for_object_tail))\n",
        "\n",
        "    sorted_by_scores_for_object_tail_indcs = torch.sort(scores_for_object_tail, descending=True)[1]\n",
        "\n",
        "    tail_objects = torch.cat((graph_data_for_object_tail.edge_index_supervision[1], graph_data_for_object_tail.edge_index_negative[1]))\n",
        "    top10_tails = tail_objects[sorted_by_scores_for_object_tail_indcs[:10]]\n",
        "    t_pred_top10.append(top10_heads)\n",
        "\n",
        "    model.eval()\n",
        "    scores_for_object_head = torch.cat(model(graph_data_for_object_head))\n",
        "\n",
        "    sorted_by_scores_for_object_head_indcs = torch.sort(scores_for_object_head, descending=True)[1]\n",
        "\n",
        "    head_objects = torch.cat((graph_data_for_object_head.edge_index_supervision[0], graph_data_for_object_head.edge_index_negative[0]))\n",
        "    top10_heads = head_objects[sorted_by_scores_for_object_head_indcs[:10]]\n",
        "    h_pred_top10.append(top10_tails)\n",
        "\n",
        "    # print('')\n",
        "    ############################################################################## 1\n",
        "    # if False:\n",
        "    #   hit_index = (\n",
        "    #             tail_objects[sorted_by_scores_for_object_head_indcs[:500]] == eval_triplet[2]\n",
        "    #           ).nonzero(as_tuple=True)[0] + 1\n",
        "    #   if hit_index.shape[0]:\n",
        "    #     print(f'Tail ranked at {hit_index.item()}')\n",
        "    #     print('-' * 30)\n",
        "    # ############################################################################### 2\n",
        "\n",
        "    # ############################################################################### 3\n",
        "    # hit_index = (\n",
        "    #             head_objects[sorted_by_scores_for_object_tail_indcs[:500]] == eval_triplet[0]\n",
        "    #           ).nonzero(as_tuple=True)[0] + 1\n",
        "    # if hit_index.shape[0]:\n",
        "    #   print(f'Head ranked at {hit_index.item()}')\n",
        "    #   print('-' * 30)\n",
        "    ############################################################################## 4\n",
        "    \n",
        "  model.train()\n",
        "  return torch.stack(h_pred_top10), torch.stack(t_pred_top10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzR8BWA0N628"
      },
      "source": [
        "#@title evaluate_hits_at_10(model, mode) FUNCTION{ form-width: \"15%\" }\n",
        "def evaluate_hits_at_10(model: GNN, mode:str) -> torch.float:\n",
        "  if mode == 'validation':\n",
        "    head_objects_top10, tail_objects_top10 = evaluation_rank(model, val_set, train_set)\n",
        "    return evaluator.eval(\n",
        "            head_objects_top10,\n",
        "            tail_objects_top10,\n",
        "            val_set,\n",
        "            False\n",
        "    )\n",
        "  elif mode == 'testing':\n",
        "    head_objects_top10, tail_objects_top10 = evaluation_rank(model, test_set, torch.cat((train_set, val_set), dim=0))\n",
        "    return evaluator.eval(\n",
        "            head_objects_top10,\n",
        "            tail_objects_top10,\n",
        "            test_set,\n",
        "            False\n",
        "          )\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}